{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python395jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
      "display_name": "Python 3.9.5 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
      }
    },
    "colab": {
      "name": "Question2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkIweUZwFS1c"
      },
      "source": [
        "# Neural Network Object Detection \n",
        "## using Caltech 256 object dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztbSgp_mFS1d"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5a4qzdsFS1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e70a601-bc58-44df-e31f-6c20d2fc0996"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "train_generator = train_datagen.flow_from_directory('256_data/256_data/training/',\n",
        "                                                    batch_size=50,\n",
        "                                               \n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "test_generator = test_datagen.flow_from_directory('256_data/256_data/testing/',\n",
        "                                                    batch_size=50,\n",
        "                                                   \n",
        "                                                    target_size=(150, 150))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21308 images belonging to 257 classes.\n",
            "Found 9299 images belonging to 257 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(inputs, filters, num_res_blocks, pool_size):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "\n",
        "    # Arguments\n",
        "        inputs (layer):         the input tensor\n",
        "        filters ([int]):        number of filters in each stage, length of list determines number of stages\n",
        "        num_res_blocks (int):   number of residual blocks per stage\n",
        "        pool_size (int):        size of the average pooling at the end\n",
        "\n",
        "    # Returns\n",
        "        output after global average pooling and flatten, ready for output\n",
        "    \"\"\"\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=filters[0])\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack, filters in enumerate(filters):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=pool_size)(x)\n",
        "    y = Flatten()(x)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def resnet_v2(inputs, filters, num_res_blocks, pool_size):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "\n",
        "    # Arguments\n",
        "        inputs (layer):         the input tensor\n",
        "        filters ([int]):        number of filters in each stage, length of list determines number of stages\n",
        "        num_res_blocks (int):   number of residual blocks per stage\n",
        "        pool_size (int):        size of the average pooling at the end\n",
        "\n",
        "    # Returns\n",
        "        output after global average pooling and flatten, ready for output\n",
        "    \"\"\"\n",
        "\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=filters[0],\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage, filters in enumerate(filters):\n",
        "        num_filters_in = filters\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=pool_size)(x)\n",
        "    y = Flatten()(x)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_resnet_v1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nimg (InputLayer)                [(None, 150, 150, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 150, 150, 16) 448         img[0][0]                        \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 150, 150, 16) 64          conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 150, 150, 16) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 150, 150, 16) 2320        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 150, 150, 16) 64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 150, 150, 16) 0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 150, 150, 16) 2320        activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 150, 150, 16) 64          conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 150, 150, 16) 0           activation[0][0]                 \n                                                                 batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 150, 150, 16) 0           add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 75, 75, 32)   4640        activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 75, 75, 32)   128         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 75, 75, 32)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 75, 75, 32)   9248        activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 75, 75, 32)   544         activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 75, 75, 32)   128         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 75, 75, 32)   0           conv2d_5[0][0]                   \n                                                                 batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 75, 75, 32)   0           add_1[0][0]                      \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 5, 5, 32)     0           activation_4[0][0]               \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 800)          0           average_pooling2d[0][0]          \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 257)          205857      flatten[0][0]                    \n==================================================================================================\nTotal params: 225,825\nTrainable params: 225,601\nNon-trainable params: 224\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(150, 150, 3, ), name='img')\n",
        "\n",
        "x = resnet_v1(inputs, [16, 32], 1, 14)\n",
        "outputs = keras.layers.Dense(257, activation = 'softmax')(x)\n",
        "\n",
        "model_resnet_v1 = keras.Model(inputs=inputs, outputs=outputs, name='simple_resnet_v1')\n",
        "model_resnet_v1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "427/427 [==============================] - 168s 373ms/step - loss: 4.8038 - accuracy: 0.1245 - val_loss: 4.4447 - val_accuracy: 0.1692\n",
            "Epoch 2/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 3.9143 - accuracy: 0.2315 - val_loss: 4.1503 - val_accuracy: 0.2042\n",
            "Epoch 3/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 3.5148 - accuracy: 0.2917 - val_loss: 3.8474 - val_accuracy: 0.2505\n",
            "Epoch 4/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 3.2352 - accuracy: 0.3348 - val_loss: 3.8919 - val_accuracy: 0.2471\n",
            "Epoch 5/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 3.0178 - accuracy: 0.3699 - val_loss: 3.7823 - val_accuracy: 0.2798\n",
            "Epoch 6/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.8349 - accuracy: 0.4009 - val_loss: 3.8480 - val_accuracy: 0.2765\n",
            "Epoch 7/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.6833 - accuracy: 0.4305 - val_loss: 3.7142 - val_accuracy: 0.2918\n",
            "Epoch 8/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.5507 - accuracy: 0.4535 - val_loss: 3.7178 - val_accuracy: 0.2916\n",
            "Epoch 9/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.4338 - accuracy: 0.4725 - val_loss: 3.4961 - val_accuracy: 0.3167\n",
            "Epoch 10/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.3385 - accuracy: 0.4919 - val_loss: 3.6728 - val_accuracy: 0.3170\n",
            "Epoch 11/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.2533 - accuracy: 0.5076 - val_loss: 3.8985 - val_accuracy: 0.3132\n",
            "Epoch 12/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 2.1666 - accuracy: 0.5210 - val_loss: 3.5732 - val_accuracy: 0.3201\n",
            "Epoch 13/50\n",
            "427/427 [==============================] - 34s 79ms/step - loss: 2.0984 - accuracy: 0.5346 - val_loss: 3.6465 - val_accuracy: 0.3309\n",
            "Epoch 14/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 2.0314 - accuracy: 0.5507 - val_loss: 3.5605 - val_accuracy: 0.3242\n",
            "Epoch 15/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.9705 - accuracy: 0.5588 - val_loss: 3.8112 - val_accuracy: 0.3152\n",
            "Epoch 16/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 1.9068 - accuracy: 0.5704 - val_loss: 3.6865 - val_accuracy: 0.3270\n",
            "Epoch 17/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.8582 - accuracy: 0.5815 - val_loss: 3.6308 - val_accuracy: 0.3392\n",
            "Epoch 18/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 1.7980 - accuracy: 0.5919 - val_loss: 4.0615 - val_accuracy: 0.3090\n",
            "Epoch 19/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 1.7512 - accuracy: 0.6030 - val_loss: 3.7672 - val_accuracy: 0.3379\n",
            "Epoch 20/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.7008 - accuracy: 0.6125 - val_loss: 3.8987 - val_accuracy: 0.3339\n",
            "Epoch 21/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.6582 - accuracy: 0.6200 - val_loss: 4.7086 - val_accuracy: 0.2426\n",
            "Epoch 22/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 1.6144 - accuracy: 0.6288 - val_loss: 3.9051 - val_accuracy: 0.3253\n",
            "Epoch 23/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 1.5682 - accuracy: 0.6411 - val_loss: 4.2705 - val_accuracy: 0.2813\n",
            "Epoch 24/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 1.5291 - accuracy: 0.6451 - val_loss: 3.9966 - val_accuracy: 0.3290\n",
            "Epoch 25/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.4925 - accuracy: 0.6567 - val_loss: 4.0347 - val_accuracy: 0.3219\n",
            "Epoch 26/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 1.4567 - accuracy: 0.6638 - val_loss: 3.9781 - val_accuracy: 0.3297\n",
            "Epoch 27/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.4166 - accuracy: 0.6689 - val_loss: 4.1706 - val_accuracy: 0.2987\n",
            "Epoch 28/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 1.3889 - accuracy: 0.6741 - val_loss: 4.6050 - val_accuracy: 0.3177\n",
            "Epoch 29/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.3513 - accuracy: 0.6846 - val_loss: 4.1143 - val_accuracy: 0.3168\n",
            "Epoch 30/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.3277 - accuracy: 0.6864 - val_loss: 3.9754 - val_accuracy: 0.3324\n",
            "Epoch 31/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 1.2949 - accuracy: 0.6961 - val_loss: 4.7213 - val_accuracy: 0.2777\n",
            "Epoch 32/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.2637 - accuracy: 0.7037 - val_loss: 4.3123 - val_accuracy: 0.3187\n",
            "Epoch 33/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 1.2328 - accuracy: 0.7084 - val_loss: 4.2692 - val_accuracy: 0.3226\n",
            "Epoch 34/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 1.2038 - accuracy: 0.7147 - val_loss: 4.5010 - val_accuracy: 0.3296\n",
            "Epoch 35/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 1.1742 - accuracy: 0.7196 - val_loss: 4.4372 - val_accuracy: 0.3226\n",
            "Epoch 36/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.1546 - accuracy: 0.7263 - val_loss: 4.5646 - val_accuracy: 0.3250\n",
            "Epoch 37/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 1.1246 - accuracy: 0.7293 - val_loss: 4.6323 - val_accuracy: 0.3053\n",
            "Epoch 38/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 1.1094 - accuracy: 0.7361 - val_loss: 4.4618 - val_accuracy: 0.3259\n",
            "Epoch 39/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 1.0773 - accuracy: 0.7428 - val_loss: 4.5576 - val_accuracy: 0.3240\n",
            "Epoch 40/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 1.0494 - accuracy: 0.7490 - val_loss: 4.5706 - val_accuracy: 0.3278\n",
            "Epoch 41/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 1.0381 - accuracy: 0.7534 - val_loss: 4.8351 - val_accuracy: 0.3114\n",
            "Epoch 42/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 1.0127 - accuracy: 0.7531 - val_loss: 4.5224 - val_accuracy: 0.3243\n",
            "Epoch 43/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 0.9976 - accuracy: 0.7599 - val_loss: 4.8681 - val_accuracy: 0.3206\n",
            "Epoch 44/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 0.9765 - accuracy: 0.7629 - val_loss: 4.7577 - val_accuracy: 0.3229\n",
            "Epoch 45/50\n",
            "427/427 [==============================] - 33s 78ms/step - loss: 0.9485 - accuracy: 0.7714 - val_loss: 4.5852 - val_accuracy: 0.3301\n",
            "Epoch 46/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 0.9369 - accuracy: 0.7735 - val_loss: 4.9665 - val_accuracy: 0.3209\n",
            "Epoch 47/50\n",
            "427/427 [==============================] - 33s 76ms/step - loss: 0.9102 - accuracy: 0.7788 - val_loss: 5.0101 - val_accuracy: 0.2993\n",
            "Epoch 48/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 0.9014 - accuracy: 0.7811 - val_loss: 4.8024 - val_accuracy: 0.3180\n",
            "Epoch 49/50\n",
            "427/427 [==============================] - 32s 76ms/step - loss: 0.8884 - accuracy: 0.7824 - val_loss: 5.0152 - val_accuracy: 0.3055\n",
            "Epoch 50/50\n",
            "427/427 [==============================] - 33s 77ms/step - loss: 0.8651 - accuracy: 0.7904 - val_loss: 5.0373 - val_accuracy: 0.3137\n"
          ]
        }
      ],
      "source": [
        "model_resnet_v1.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
        "                  optimizer=keras.optimizers.RMSprop(),\n",
        "                  metrics=['accuracy'])\n",
        "history = model_resnet_v1.fit(train_generator,\n",
        "                        epochs=50,\n",
        "                        validation_data = test_generator)"
      ]
    }
  ]
}